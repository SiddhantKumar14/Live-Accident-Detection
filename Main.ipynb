{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.python.keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers import GlobalMaxPool2D\n",
    "from tensorflow.python.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers import Conv2D\n",
    "from tensorflow.python.keras.layers import Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.utils import np_utils, generic_utils\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 30, 96, 144, 32)\n",
      "(None, 30, 48, 72, 32)\n",
      "(None, 30, 48, 72, 64)\n",
      "(None, 30, 24, 36, 64)\n",
      "(None, 30, 24, 36, 128)\n",
      "(None, 30, 12, 18, 128)\n",
      "(None, 30, 12, 18, 256)\n",
      "(None, 30, 12, 18, 256)\n",
      "(None, 30, 1, 1, 256)\n",
      "(None, 30, 256)\n",
      "(None, 30, 256)\n",
      "(None, 256)\n",
      "(None, 256)\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 2\n",
    "dropout_rate = 0.2\n",
    "classes = ['NotCrash', 'Crash']\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "strides = (1,1,1)\n",
    "kernel_size = (3, 3, 3)\n",
    "\n",
    "model.add(Conv3D(32, kernel_size, strides=strides, activation='relu', padding='same', input_shape=(30, 96, 144, 3)))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv3D(64, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv3D(128, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv3D(256, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv3D(256, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(1,12,18)))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Reshape((30, 256)))\n",
    "print(model.output_shape)\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "print(model.output_shape)\n",
    "model.add(LSTM(256))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title=\"img\"):\n",
    "    cv2.imshow(title, img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize frames\n",
    "\n",
    "def resize_frame(frame, size):\n",
    "    frame = img.imread(frame)\n",
    "    frame = cv2.resize(frame, size)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_datagen import VideoDataGenerator\n",
    "\n",
    "gen = VideoDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGB MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001)\n",
    "model.compile(optimizer=sgd, loss= 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 873 videos belonging to 2 classes.\n",
      "Found 78 videos belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_path = '/home/siddhant/Datasets/Crash Dataset/Final_Preprocessed/train'\n",
    "validation_path = '/home/siddhant/Datasets/Crash Dataset/Final_Preprocessed/validation'\n",
    "\n",
    "batchsize = 1\n",
    "training_set = gen.flow_from_directory(training_path, target_size=(128, 192), batch_size=batchsize, clip_size=30)\n",
    "validation_set = gen.flow_from_directory(validation_path, target_size=(128, 192), batch_size=4, clip_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "per_process_gpu_memory_fraction: 0.33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.33)\n",
    "\n",
    "#tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "872/872 [==============================] - 587s 673ms/step - loss: 0.6672 - accuracy: 0.6061 - val_loss: 0.6959 - val_accuracy: 0.5769\n",
      "Epoch 2/20\n",
      "872/872 [==============================] - 588s 675ms/step - loss: 0.6417 - accuracy: 0.5900 - val_loss: 0.6511 - val_accuracy: 0.5705\n",
      "Epoch 3/20\n",
      "872/872 [==============================] - 586s 672ms/step - loss: 0.6166 - accuracy: 0.6044 - val_loss: 0.6445 - val_accuracy: 0.5705\n",
      "Epoch 4/20\n",
      "872/872 [==============================] - 585s 671ms/step - loss: 0.6094 - accuracy: 0.6181 - val_loss: 0.6628 - val_accuracy: 0.5897\n",
      "Epoch 5/20\n",
      "872/872 [==============================] - 581s 666ms/step - loss: 0.6079 - accuracy: 0.6164 - val_loss: 0.7907 - val_accuracy: 0.5449\n",
      "Epoch 6/20\n",
      "872/872 [==============================] - 579s 664ms/step - loss: 0.6081 - accuracy: 0.6055 - val_loss: 0.6461 - val_accuracy: 0.5769\n",
      "Epoch 7/20\n",
      "872/872 [==============================] - 581s 666ms/step - loss: 0.5948 - accuracy: 0.6216 - val_loss: 0.6491 - val_accuracy: 0.5577\n",
      "Epoch 8/20\n",
      "872/872 [==============================] - 582s 667ms/step - loss: 0.5870 - accuracy: 0.6307 - val_loss: 0.7954 - val_accuracy: 0.5321\n",
      "Epoch 9/20\n",
      "104/872 [==>...........................] - ETA: 8:31 - loss: 0.5899 - accuracy: 0.6731"
     ]
    }
   ],
   "source": [
    "training_history_rgb2 = model.fit_generator(training_set, use_multiprocessing=True,\n",
    "                                       epochs =20,validation_data = validation_set , verbose = 1 , validation_steps = 20,\n",
    "                                       steps_per_epoch=872)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model2-sgd-0001-20epochs-orgsize.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickling_on = open(\"history_rgb_2orgsize.pickle\",\"wb\")\n",
    "pickle.dump(training_history_rgb2.history, pickling_on)\n",
    "pickling_on.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history_flow_sized = model.fit_generator(training_set, use_multiprocessing=True,\n",
    "                                       epochs =20,validation_data = validation_set , verbose = 1 , validation_steps = 1,\n",
    "                                       steps_per_epoch=872//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model-flow-sgd-0001-50epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 videos belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_path = '/home/siddhant/Datasets/Crash Dataset/Final_Preprocessed/test'\n",
    "\n",
    "testing_set = gen.flow_from_directory(testing_path, target_size=(96, 144), batch_size=1, clip_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7291666666666666\n"
     ]
    }
   ],
   "source": [
    "# calculating test result accuracy\n",
    "\n",
    "test_size = len(os.listdir(f'{testing_path}/Crash')) + len(os.listdir(f'{testing_path}/NotCrash'))\n",
    "iterations = 0\n",
    "accuracy = []\n",
    "while True:\n",
    "    inst = next(testing_set)\n",
    "    score = model.evaluate(inst[0], inst[1], verbose = 0)\n",
    "    accuracy.append(score[1])\n",
    "    iterations += 1\n",
    "    \n",
    "    if iterations == test_size:\n",
    "        break\n",
    "print(sum(accuracy)/len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 30, 96, 144, 32)   2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 96, 144, 32)   128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 30, 48, 72, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 30, 48, 72, 64)    55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 48, 72, 64)    256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 30, 24, 36, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 30, 24, 36, 128)   221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 24, 36, 128)   512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 30, 12, 18, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 30, 12, 18, 256)   884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 12, 18, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 30, 12, 18, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 12, 18, 256)   1024      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 30, 1, 1, 256)     0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 256)           525312    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 4,053,890\n",
      "Trainable params: 4,052,418\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ece01b010d4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'classes'"
     ]
    }
   ],
   "source": [
    "model.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class =  NotCrash Precision =  60.540771484375 %\n",
      "Class =  NotCrash Precision =  62.795281410217285 %\n",
      "Class =  NotCrash Precision =  60.591113567352295 %\n",
      "Class =  NotCrash Precision =  67.68972277641296 %\n",
      "Class =  NotCrash Precision =  78.3884048461914 %\n",
      "Class =  NotCrash Precision =  68.09093356132507 %\n",
      "Class =  NotCrash Precision =  71.17609977722168 %\n",
      "Class =  NotCrash Precision =  69.8011040687561 %\n",
      "Class =  NotCrash Precision =  89.85544443130493 %\n",
      "Class =  NotCrash Precision =  91.48525595664978 %\n",
      "Class =  Crash Precision =  73.48454594612122 %\n",
      "Class =  Crash Precision =  88.89908194541931 %\n",
      "Class =  Crash Precision =  89.17043805122375 %\n",
      "Class =  Crash Precision =  67.25341081619263 %\n",
      "Class =  NotCrash Precision =  92.02522039413452 %\n",
      "Class =  NotCrash Precision =  91.55519008636475 %\n",
      "Class =  NotCrash Precision =  94.72222924232483 %\n",
      "Class =  NotCrash Precision =  95.68073153495789 %\n",
      "Class =  NotCrash Precision =  95.51900625228882 %\n",
      "Class =  NotCrash Precision =  93.65037679672241 %\n",
      "Class =  NotCrash Precision =  79.91153001785278 %\n"
     ]
    }
   ],
   "source": [
    "to_predict = []\n",
    "\n",
    "model.load_weights('best.h5')\n",
    "num_frames = 0\n",
    "cap = cv2.VideoCapture('/home/siddhant/Codes/Accident Detection/accident3.mp4')\n",
    "\n",
    "#cap.set(12, 50)\n",
    "#cap.set(6, 10)\n",
    "#cap.set(cv2.CAP_PROP_FPS, 10)\n",
    "\n",
    "preds = []\n",
    "\n",
    "classe = ''\n",
    "import time\n",
    "fps = 30\n",
    "counter  = 0\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame_cp = cv2.resize(frame, (144, 96))\n",
    "    \n",
    "    if counter%1 == 0:\n",
    "        to_predict.append(frame_cp)\n",
    "    counter += 1\n",
    "    predict = 0\n",
    "    if len(to_predict) == 30:\n",
    "\n",
    "        frame_to_predict = [[]]\n",
    "        frame_to_predict[0] = np.array(to_predict, dtype=np.float32)\n",
    "\n",
    "\n",
    "        predict = model.predict(np.array(frame_to_predict))\n",
    "        classe = classes[np.argmax(predict)]\n",
    "        if np.amax(predict) > 0.60:\n",
    "            print('Class = ',classe, 'Precision = ', np.amax(predict)*100,'%')\n",
    "            preds.append(np.argmax(predict))\n",
    "           # with open('gesture.pkl','wb') as f:\n",
    "                #pickle.dump(np.argmax(predict), f)\n",
    "        if len(preds) >= 10:\n",
    "            preds = preds[8:9]\n",
    "\n",
    "        to_predict = []\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, classe, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255),1,cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Live Accident Detection',frame)\n",
    "    if cv2.waitKey(int( (1 / int(fps)) * 1000)) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSamples(pathToSample, resize_dim = (144, 96)):\n",
    "    # pathToSample points to dir containing the frames\n",
    "    frames = os.listdir(pathToSample)\n",
    "    frames.sort()\n",
    "    sample = []\n",
    "    for frame in frames:\n",
    "        im = cv2.imread(f'{pathToSample}/{frame}')\n",
    "        im = cv2.resize(im, resize_dim)\n",
    "        sample.append(im)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model-sgd-0001-20epochs3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95695245, 0.04283412]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = readSamples('/home/siddhant/Datasets/Crash Dataset/Final_Preprocessed/test/NotCrash/221')\n",
    "\n",
    "sample = [sample]\n",
    "sample = np.array(sample, dtype=np.float32)\n",
    "model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30, 96, 144, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['320', '38', '108', '66', '137', '263', '165', '249', '94', '151', '123', '207', '291', '305', '221', '334', '80', '179', '235', '193', '52', '277', '10', '24']\n",
      "['9', '452', '153', '605', '331', '36', '361', '544', '88', '140', '23', '75', '422', '114', '269', '498', '376', '437', '223', '514', '284', '62', '391', '574', '208', '101', '238', '467', '254', '406', '166', '315', '179', '193', '346', '49', '127', '529', '300', '559', '483', '589']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('/home/siddhant/Datasets/Crash Dataset/Final_Preprocessed/test/NotCrash/'))\n",
    "print(os.listdir('/home/siddhant/Datasets/Crash Dataset/Final_Preprocessed/test/Crash/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "vid_dir = ''\n",
    "\n",
    "images = glob.glob(os.path.join('/home/siddhant/Codes/Accident Detection/221/','*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/siddhant/Codes/Accident Detection/221/003.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/024.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/025.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/013.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/001.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/004.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/008.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/010.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/000.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/022.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/023.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/007.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/002.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/006.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/009.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/028.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/018.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/016.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/019.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/015.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/020.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/017.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/011.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/021.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/029.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/005.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/026.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/012.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/014.png',\n",
       " '/home/siddhant/Codes/Accident Detection/221/027.png']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
