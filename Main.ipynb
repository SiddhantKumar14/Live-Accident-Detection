{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.python.keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers import GlobalMaxPool2D\n",
    "from tensorflow.python.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers import Conv2D\n",
    "from tensorflow.python.keras.layers import Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.utils import np_utils, generic_utils\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 30, 96, 144, 32)\n",
      "(None, 30, 48, 72, 32)\n",
      "(None, 30, 48, 72, 64)\n",
      "(None, 30, 24, 36, 64)\n",
      "(None, 30, 24, 36, 128)\n",
      "(None, 30, 12, 18, 128)\n",
      "(None, 30, 12, 18, 256)\n",
      "(None, 30, 12, 18, 256)\n",
      "(None, 30, 1, 1, 256)\n",
      "(None, 30, 256)\n",
      "(None, 30, 256)\n",
      "(None, 256)\n",
      "(None, 256)\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 2\n",
    "dropout_rate = 0.2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "strides = (1,1,1)\n",
    "kernel_size = (3, 3, 3)\n",
    "\n",
    "model.add(Conv3D(32, kernel_size, strides=strides, activation='relu', padding='same', input_shape=(30, 96, 144, 3)))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv3D(64, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv3D(128, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv3D(256, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv3D(256, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(1,12,18)))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Reshape((30, 256)))\n",
    "print(model.output_shape)\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "print(model.output_shape)\n",
    "model.add(LSTM(256))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title=\"img\"):\n",
    "    cv2.imshow(title, img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize frames\n",
    "\n",
    "def resize_frame(frame, size):\n",
    "    frame = img.imread(frame)\n",
    "    frame = cv2.resize(frame, size)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_datagen import VideoDataGenerator\n",
    "\n",
    "gen = VideoDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.0001)\n",
    "model.compile(optimizer=sgd, loss= 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2564 videos belonging to 2 classes.\n",
      "Found 225 videos belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_path = '/home/siddhant/Datasets/Crash Dataset/Final_Preprocessed/train'\n",
    "validation_path = '/home/siddhant/Datasets/Crash Dataset/Final_Preprocessed/validation'\n",
    "\n",
    "batchsize = 2\n",
    "training_set = gen.flow_from_directory(training_path, target_size=(96, 144), batch_size=batchsize, clip_size=30)\n",
    "validation_set = gen.flow_from_directory(validation_path, target_size=(96, 144), batch_size=8, clip_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0:1.0, 1:3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1282/1282 [==============================] - 998s 778ms/step - loss: 0.6227 - accuracy: 0.6899 - val_loss: 0.5634 - val_accuracy: 0.6875\n",
      "Epoch 2/20\n",
      "1282/1282 [==============================] - 1003s 782ms/step - loss: 0.5303 - accuracy: 0.8309 - val_loss: 0.4947 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "1282/1282 [==============================] - 1003s 782ms/step - loss: 0.4522 - accuracy: 0.8752 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "1282/1282 [==============================] - 1000s 780ms/step - loss: 0.3726 - accuracy: 0.9119 - val_loss: 0.2808 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1282/1282 [==============================] - 1001s 781ms/step - loss: 0.2899 - accuracy: 0.9405 - val_loss: 0.1737 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1282/1282 [==============================] - 992s 774ms/step - loss: 0.2412 - accuracy: 0.9524 - val_loss: 0.2633 - val_accuracy: 0.8750\n",
      "Epoch 7/20\n",
      "1282/1282 [==============================] - 992s 774ms/step - loss: 0.2032 - accuracy: 0.9563 - val_loss: 0.2318 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1282/1282 [==============================] - 990s 772ms/step - loss: 0.1595 - accuracy: 0.9702 - val_loss: 0.2102 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1282/1282 [==============================] - 987s 770ms/step - loss: 0.1292 - accuracy: 0.9809 - val_loss: 0.1044 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1282/1282 [==============================] - 987s 770ms/step - loss: 0.1152 - accuracy: 0.9780 - val_loss: 0.1041 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1282/1282 [==============================] - 978s 763ms/step - loss: 0.0943 - accuracy: 0.9862 - val_loss: 0.0728 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1282/1282 [==============================] - 978s 763ms/step - loss: 0.0805 - accuracy: 0.9879 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1282/1282 [==============================] - 975s 761ms/step - loss: 0.0673 - accuracy: 0.9914 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1282/1282 [==============================] - 978s 763ms/step - loss: 0.0652 - accuracy: 0.9906 - val_loss: 0.2768 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "1282/1282 [==============================] - 979s 764ms/step - loss: 0.0586 - accuracy: 0.9908 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1282/1282 [==============================] - 979s 764ms/step - loss: 0.0456 - accuracy: 0.9941 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1282/1282 [==============================] - 977s 762ms/step - loss: 0.0466 - accuracy: 0.9928 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1282/1282 [==============================] - 979s 763ms/step - loss: 0.0476 - accuracy: 0.9920 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1282/1282 [==============================] - 976s 761ms/step - loss: 0.0403 - accuracy: 0.9928 - val_loss: 0.0666 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1282/1282 [==============================] - 979s 764ms/step - loss: 0.0361 - accuracy: 0.9947 - val_loss: 0.3355 - val_accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit_generator(training_set, use_multiprocessing=True,\n",
    "                                       epochs =20,validation_data = validation_set , verbose = 1 , validation_steps = 1,\n",
    "                                       steps_per_epoch=2564//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model-sgd-0001-20epochs2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model-sgd-0001-20epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 videos belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_path = '/home/siddhant/Datasets/Crash Dataset/Final_Preprocessed/test'\n",
    "\n",
    "testing_set = gen.flow_from_directory(testing_path, target_size=(96, 144), batch_size=10, clip_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = next(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6991062760353088\n",
      "Test accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(inst[0], inst[1], verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 30, 96, 144, 32)   2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 96, 144, 32)   128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 30, 48, 72, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 30, 48, 72, 64)    55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 48, 72, 64)    256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 30, 24, 36, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 30, 24, 36, 128)   221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 24, 36, 128)   512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 30, 12, 18, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 30, 12, 18, 256)   884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 12, 18, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 30, 12, 18, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 12, 18, 256)   1024      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 30, 1, 1, 256)     0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 256)           525312    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 4,053,890\n",
      "Trainable params: 4,052,418\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class =  Crash Precision =  93.42271685600281 %\n",
      "Class =  Crash Precision =  91.50057435035706 %\n",
      "Class =  Crash Precision =  93.78187656402588 %\n"
     ]
    }
   ],
   "source": [
    "to_predict = []\n",
    "classes = ['Crash', 'NotCrash']\n",
    "\n",
    "model.load_weights('model-sgd-0001-20epochs.h5')\n",
    "num_frames = 0\n",
    "cap = cv2.VideoCapture('/home/siddhant/Datasets/Crash Dataset/crashCompilationTesting.mp4')\n",
    "\n",
    "#cap.set(12, 50)\n",
    "#cap.set(6, 10)\n",
    "#cap.set(cv2.CAP_PROP_FPS, 10)\n",
    "\n",
    "preds = []\n",
    "\n",
    "classe = ''\n",
    "import time\n",
    "fps = 30\n",
    "counter  = 0\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame_cp = frame\n",
    "    \n",
    "    frame_cp = cv2.resize(frame, (144, 96))\n",
    "    \n",
    "    if counter%5 == 0:\n",
    "        to_predict.append(frame_cp)\n",
    "    counter += 1\n",
    "    predict = 0\n",
    "    if len(to_predict) == 30:\n",
    "\n",
    "        frame_to_predict = [[]]\n",
    "        frame_to_predict[0] = np.array(to_predict, dtype=np.float32)\n",
    "\n",
    "\n",
    "        predict = model.predict(np.array(frame_to_predict))\n",
    "        classe = classes[np.argmax(predict)]\n",
    "        if np.amax(predict) > 0.60:\n",
    "            print('Class = ',classe, 'Precision = ', np.amax(predict)*100,'%')\n",
    "            preds.append(np.argmax(predict))\n",
    "           # with open('gesture.pkl','wb') as f:\n",
    "                #pickle.dump(np.argmax(predict), f)\n",
    "        if len(preds) >= 10:\n",
    "            preds = preds[8:9]\n",
    "\n",
    "        to_predict = []\n",
    "        time.sleep(0.1)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, classe, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0),1,cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Live Accident Detection',frame)\n",
    "    if cv2.waitKey(int( (1 / int(fps)) * 1000)) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSamples(pathToSample, resize_dim = (144, 96)):\n",
    "    # pathToSample points to dir containing the frames\n",
    "    frames = os.listdir(pathToSample)\n",
    "    frames.sort()\n",
    "    sample = []\n",
    "    for frame in frames:\n",
    "        im = cv2.imread(f'{pathToSample}/{frame}')\n",
    "        im = cv2.resize(im, resize_dim)\n",
    "        sample.append(im)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9771811 , 0.02018946]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = readSamples('/home/siddhant/Datasets/Crash Dataset/Final_Preprocessed/test/Crash/22')\n",
    "sample = [sample]\n",
    "sample = np.array(sample, dtype=np.float32)\n",
    "model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30, 96, 144, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
